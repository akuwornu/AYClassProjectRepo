

                                                                                                 Page 1 of 6
        House Oversight & Accountability Subcommittee Issues Testimony From Abundance Institute Artificial
                                         Intelligence Policy Head Chilson




   House Oversight & Accountability Subcommittee Issues Testimony From
       Abundance Institute Artificial Intelligence Policy Head Chilson
                                                     Targeted News Service
                                           March 28, 2024 Thursday 9:10 AM EST



Copyright 2024 Targeted News Service LLC All Rights Reserved




Length: 3418 words
Byline: Targeted News Service
Dateline: WASHINGTON

Body


The House Oversight and Accountability Subcommittee on Cybersecurity, Information Technology and Government
Innovation issued the following testimony by Neil Chilson, head of artificial intelligence policy at the Abundance
Institute, involving a hearing on March 21, 2024, entitled "White House Overreach on AI":

***

Thank you, Chairwoman Mace, Ranking Member Connolly, and subcommittee members for having me today to talk
about the Biden Executive Order on Artificial Intelligence. I am Neil Chilson, the Head of AI Policy at the
Abundance Institute, a former Chief Technologist at the Federal Trade Commission (FTC), and a past advisor to
acting FTC Chair Maureen K. Ohlhausen.

The Abundance Institute is a mission-driven nonprofit dedicated to creating an environment for emerging
technologies to germinate, develop, and thrive in order to perpetually expand widespread human prosperity and
abundance.

Now is a crucial time for this mission, as the many technologies of artificial intelligence launch us toward greater
prosperity and abundance. Intelligence is our most vital resource. It is the tool with which humanity has overcome
countless challenges. Every breakthrough technology, scientific discovery, business success, art piece, and literary
work stems from human intellect.

Often, turning intellect into material progress involves massive collaboration and coordination, generating intelligent
outcomes beyond any one person's capabilities. Tools amplifying human intelligence, therefore, have vast potential.
AI promises to help humanity create a healthier, safer, more productive, more artistic, more interesting, and more
enjoyable world.

                                                                                                Page 2 of 6
       House Oversight & Accountability Subcommittee Issues Testimony From Abundance Institute Artificial
                                        Intelligence Policy Head Chilson

However, to develop and deploy AI to its fullest potential, we need the right cultural and regulatory environment.
The Biden Administration's recent "Executive Order on the Safe, Secure, and Trustworthy Development and Use of
Artificial Intelligence" does not cultivate that environment; indeed, its likely effect is to add regulatory burdens to
AI and to software development generally. Most importantly, the EO imposes these new burdens without
Congressional authorization.

***

Background on the Unprecedented AI Executive Order

On October 30, 2023, President Biden issued an "Executive Order on the Safe, Secure, and Trustworthy
Development and Use of Artificial Intelligence."2 The EO is a dense roadmap for government intervention over
the next several years, complete with dozens of deadlines, reports, and policy deliverables. Its length and specificity
make its regulatory impact unprecedented.

The AI Executive Order is unusual in form. It is atypically long, just shy of 20,000 words. Of the over nine thousand
Presidential executive orders identified and collected by the American Presidency Project at University of California-
Santa Barbara, the AI EO is the third longest Executive Order in American history.3 The only EOs that are longer
are a 1951 President Truman EO setting forth the entire manual for military Court Martial Procedures, and
President Carter's 1980 update to that manual.4 Most executive orders are much shorter than the AI EO, which is
88 times longer than the median executive order. Indeed, many of the most important executive orders are less
than a dozen pages long.5

The EO is also unusual in substance. News coverage has focused on the EO's obligations for companies that
develop large foundational models and the companies that supply the computational resources to develop such
models. These obligations deserve attention, especially from Congressional oversight committees like this one,
because, as I will discuss later, the EO imposes that new regulation without any Congressional authorization. Also
worth discussing, however, is the EO directives to dozens of agencies and federal officials to engage in a wide
range of activities to govern AI. By my count these activities include 136 different deliverables such as: seventeen
reports, thirty-two new guidance documents, eleven proposed regulations, and dozens of new projects, processes,
plans, and events.

Executive orders have had many different functions historically, but it is rare for a single EO to issue dozens of
specific new policy directives to dozens of agencies and official.6 Reshaping the entire federal government's role on
a single domestic policy topic is traditionally and constitutionally Congress's job.

Not all of the AI EO-directed actions are unauthorized. Many of the directed actions are information gathering
efforts or exhortations to apply existing regulatory authority as necessary and relevant to this new technology. While
one might question whether such efforts are worth the costs or will produce useful results, the President has the
authority to issue them. Some of these authorized actions are advisable. Indeed, the EO is on its strongest legal
and policy grounds when it directs the Federal government to assess and manage its own use of this new
technology.7

Had the EO focused on the government's own use of AI, it would have been on solid legal ground. However, the
EO goes far beyond that safe territory.

***

Misuse of the Defense Production Act

EO Section 4.2 directs the Secretary of Commerce to impose new obligations on private companies. These
obligations would require companies "developing or demonstrating an intent to develop potential dual-use
foundation models" to provide the government with significant amounts of highly sensitive business and technical
information.8 The types of information that would seem to be required include, among other things:

                                                                                                Page 3 of 6
       House Oversight & Accountability Subcommittee Issues Testimony From Abundance Institute Artificial
                                        Intelligence Policy Head Chilson

* all ongoing or planned training of certain AI models;

* cybersecurity measures to protect training integrity and access to trained models;

* ownership and possession of certain AI models;

* the performance of certain AI models in government-established red-team testing regimes; and

* any mitigations to improve the performance of certain AI models on these government-established tests.

Section 4.2(a) also requires that companies that "acquire, develop, or purchase" computing clusters above a certain
threshold must report the location and computing power of such clusters.

As a letter from twenty State Attorneys General to NTIA summarizes it, Section 4.2 of the EO requires such
companies "to report to the federal government on their 'ongoing or planned activities,' to conduct various tests
based on federal regulations, and to report to the government on the results of those tests."9

The EO imposes these new obligations in pursuit of "the continuous availability of safe, reliable, and effective AI in
accordance with the Defense Production Act."10 This generic reference to the Defense Production Act (DPA) is the
only statutory authority cited for the regulations imposed in Section 4.2(a). But the Defense Production Act cannot
support these new obligations, for at least three reasons.

First, the Defense Production Act empowers the President in emergencies to spur defense-related production. It
does not permit the President to micromanage industries on an "ongoing" basis.11 The DPA is a Korean War-era
law intended to ensure the government has access to materials and services necessary to defend the country. It is
typically used to put government contracts at the front of the manufacturing line (Title I), and sometimes to spend
money to expand productive capacity in defense-essential capabilities (Title III).12 Here, though, the Biden
administration is not using the DPA to spur the production of AI or computing facilities for government use and to
support national security. Instead, the EO deploys the DPA to demand highly confidential documents from
companies that may not even have a contractual relationship with the government and to drive the adoption of
government-established quality control measures for commercially available products to be used by normal
Americans and businesses.

The EO does not identify which specific DPA provision authorizes EO Section 4.2. It would appear that Section 705
of the DPA is the most relevant.13 However, that section is most commonly used for "industrial base assessments"
to inform where Title III authorities need to be used to expand productive capacity.14 Yet Section 4.2 does not
expand AI production capacity; if anything, it discourages production by imposing new requirements on foundational
models above a specific capacity.15

The primary products being "produced" by this use of the Defense Production Act will be reams of filings to the
Federal Government and a legal precedent for unilateral Presidential regulation of the economy.

Second, the DPA is not a shortcut around the U.S. Constitution. The Constitution assigns the power to make the
laws to Congress, not to the Executive branch.16 Indeed, Congress is actively considering a swath of artificial
intelligence-related bills.17 If Congress chooses to act deliberately on a specific issue, the President cannot
therefore usurp that decision by stepping in and regulating, with merely a general reference to the DPA.

Third, the DPA is an emergency power, but there is no emergency here. Current AI developments are rapid, but
they build on a long trend in machine learning that dates back at least to the development of neural networks
algorithms in the 1970s.18 The transformer architecture that underlies many increasingly popular generative AI
tools, such as ChatGPT, was released by Google researchers in August 2017.19

The EO claims that "[t]he rapid speed at which AI capabilities are advancing compels the United States to lead in
this moment for the sake of our security, economy, and society."20 But continued rapid AI development poses no

                                                                                                Page 4 of 6
       House Oversight & Accountability Subcommittee Issues Testimony From Abundance Institute Artificial
                                        Intelligence Policy Head Chilson

emergency threat to U.S. leadership because the U.S. already has a significant lead in the development of AI and
AI companies.21

The EO offers no indication of what emergency it seeks to address or when it will end. Indeed, Section 4.2 imposes
"ongoing" obligations, suggesting the Administration sees no end to the alleged emergency.

The EO does list potential societal harms, worrying that AI misuse could "exacerbate societal harms such as fraud,
discrimination, bias, and disinformation; displace and disempower workers; [and] stifle competition."22 Section 2
elaborates on many of these potential harms. But even with elaboration none of these look like the kinds of
emergencies the DPA is intended to address. Most are traditional consumer protection, civil rights, labor, and
competition issues where Congress has proven willing and able to create legislation.23 While such issues are
important, they are not national security emergencies that justify upending our democratic tradition of legislative
lawmaking.

Section 1 does mention that AI could "pose risks to national security." Section 2 fleshes out these concerns:
"Artificial Intelligence must be safe and secure," says the EO, which "requires addressing AI systems' most
pressing security risks -- including with respect to biotechnology, cybersecurity, critical infrastructure, and other
national security dangers."24

However, if Section 4.2 is intended to reduce those risks to national security, its use of the DPA still overreaches.
The DPA is intended to reduce one very specific type of risk to national security: threats to "the ability of the
domestic industrial base to supply materials and services" needed for national defense and disaster recovery.25
The EO does not mention such risk. Even had it done so, there is no emergency shortfall in the ability of the
domestic industrial base to supply AI capabilities; indeed, "AI capabilities are advancing" at a "rapid speed."26 In
sum, Section 4.2 of the EO imposes new regulations on private companies that are not and cannot be justified by a
general reference to the Defense Production Act.

***

Expansive Definition of AI and the Effect on the Software Industry

Outside of the improper use of the DPA to impose direct regulation on some AI and hardware companies, the EO's
broad definition of AI and its many directives to Federal agencies threaten to refactor software development in the
United States.

Despite the fact that there is no expert consensus on the definition of AI,27 the EO sets forth the following definition
AI:

The term "artificial intelligence" or "AI" has the meaning set forth in 15 U.S.C. 9401(3): a machine-based system
that can, for a given set of human-defined objectives, make predictions, recommendations, or decisions influencing
real or virtual environments.

Artificial intelligence systems use machine- and human-based inputs to perceive real and virtual environments;
abstract such perceptions into models through analysis in an automated manner; and use model inference to
formulate options for information or action.28

This broad definition includes far more software than the large language models or "generative AI" tools that have
generated massive attention since the launch of ChatGPT. Indeed, as former Microsoft executive Steven Sinofsky
has pointed out, the EO's AI definition likely covers 1980's era financial software.29 It also appears to cover
algorithms used for: social media content moderation and feeds; targeted advertising; search engine algorithms; in-
game bots; insurance models; any number of financial tools; and more. In short, the EO defines AI to include a wide
swath of software.

The EO borrows this definition from the National AI Initiative Act of 2020, a bill intended to boost government
agency spending on AI technology.30 There, a vague and over-inclusive definition received little attention because

                                                                                                Page 5 of 6
       House Oversight & Accountability Subcommittee Issues Testimony From Abundance Institute Artificial
                                        Intelligence Policy Head Chilson

it posed little risk: no legal consequences followed for software developers that entirely ignored the National AI
Initiative Act.

Here, companies will not have the luxury of ignorance. Dozens of agencies will be using the EO's expansive
definition to develop new guidance and regulations.

Future software developers could labor under several categories of obligations from the EO separate from the
already-discussed mandates in Section 4.2. The EO's other provisions fall into three categories: 1) requirements on
how agencies should act as purchasers and users of AI; 2) requests or suggestions that agencies apply their
existing authorities to this new topic area; and 3) calls for agencies to issue guidance, best practices, standards,
and other non-mandatory soft-law provisions.

Thus, portions of the EO will affect companies that sell software to the federal government or those that sell private
sector software for use in critical infrastructure or a regulated industry, such as human resources, bioengineering,
transportation, education, healthcare, housing, or energy.

For example, the EO directs the Secretary of Health and Human Services to establish quality assurance programs
for software in the health and human services sector.31 Specifically, HHS is to "determine whether AI-enabled
technologies in the health and human services sector maintain appropriate levels of quality, including ... enabling
pre-market assessment and post-market oversight of AI-enabled healthcare-technology algorithmic system
performance against real-world data."32 The broad definition of AI in the Executive Order means every healthcare
software provider ought to follow such developments and ensure their views are represented to HHS.

The EO also seeks to impose new obligations on software users. For example, the EO charges the Secretary of
Labor with "[d]evelop[ing] and publish[ing] principles and best practices for employers that could be used to mitigate
AI's potential harms to employees' well-being and maximize its potential benefits."33 Given the broad definition of
AI, this proceeding could impact every U.S. employer.

Certain initiatives in the EO will apply across the economy. For example, the EO "encourages" the Federal Trade
Commission (FTC) to "consider [using] its rulemaking authority .... to ensure fair competition in the AI marketplace
and to ensure that consumers and workers are protected from harms that may be enabled by the use of AI."34 The
FTC is nominally an independent agency overseen by Congress, which is why the EO "encourages" action rather
than directing it.

But the President nominated the commissioners and his encouragement will usually drive results.

Much of the agency response to the EO will be in the form of guidance documents. Industry may be tempted to
ignore the development and deployment of such non-mandatory instruments. That would be a mistake, because
such guidance documents will lay the groundwork for follow-on action by other parts of the federal government. For
example, the FTC has often used guidance in its law enforcement actions. As the U.S.'s general consumer
protection agency, the FTC is charged with redressing "unfair and deceptive acts and practices."35 If a company
claims to follow specific standards or guidelines but doesn't, the FTC may have a deception case. And the FTC has
often relied on guidance and standards when establishing whether a particular business practice is unfair. For
example, in data security cases, the FTC often points to established best practices to determine whether a
company that has suffered a data breach was acting "unfairly." If the FTC determines that a company was not
following best practices, that could lead to significant financial costs and mandatory FTC-enforced constraints on
the business's operations.

There are other ways that the EO could have a real impact on the broader software industry. For example, the EO
charges some agencies with proposing legislation. And the testing standards that NIST is charged with developing
could also be adopted by courts as a standard of care in tort cases.

Meanwhile, the EO's application to open source software is unclear. The order's expansive definition of AI means
that open source systems could struggle to comply with new regulations.

                                                                                               Page 6 of 6
      House Oversight & Accountability Subcommittee Issues Testimony From Abundance Institute Artificial
                                       Intelligence Policy Head Chilson

In an open letter, many leading AI technologists, academics, and investors pushed back against the EO, describing
it as a threat to open source software and systems as a competitive counterbalance to proprietary platforms.36

Such comprehensive regulation of the development and use of software would be a new approach for the US.
There is no Federal Computer Agency responsible for regulating software.

Instead, we address harms involving the use of software through a combination of broad-based laws governing
fraud, civil rights, unfair practices, or unsafe products. Tort law such as negligence and product liability cases
provide court-based remedies for other harms.

The existing diverse set of approaches is appropriate, because software is so broad in application that no single
agency has the necessary specialized knowledge to govern every application of the technology. As a result, rather
than regulating software generally, the U.S. regulates certain industries, most of which happen to use software,
such as medical devices and aviation. And where academics, researchers, and practitioners need to coordinate on
technical issues, they have used non-governmental standard-setting organizations like the ACM and IEEE to
define, for example, "floating point operations."37

Motivated by concerns over generative artificial intelligence, the EO directs a new regime of regulatory oversight
for the software industry overall. The dozens of guidance and best practices documents spurred by the EO will have
legal consequences for the software development industry and even for software users.

Even if it were desirable to revise the U.S. approach to software regulation, using a Presidential Executive Order to
render such a dramatic change to the regulatory landscape is inappropriate.

Such a potential sea change in one of America's most vibrant industries deserves to be considered, refined, and
decided by Congress.

Conclusion

The Executive Order is largely a missed opportunity to set forth a positive vision for the future of AI use while
shoring up civil liberties from government misuse of these technologies. But not only does the EO strike the wrong
policy balance - it also usurps Congress, abusing the DPA to impose new regulations and spurring a deluge of
regulatory action that will affect the entire software industry. This overreach calls for continued congressional
oversight, democratic accountability, and potentially legislative or judicial course correction.

Thank you, and I look forward to your questions.

***

URL: Abundance Institute

***

Original text here: https://oversight.house.gov/wp-content/uploads/2024/03/Chilson-Testimony.pdf

Copyright Targeted News Services

MSTRUCK-8550324 MSTRUCK


Load-Date: March 28, 2024


  
